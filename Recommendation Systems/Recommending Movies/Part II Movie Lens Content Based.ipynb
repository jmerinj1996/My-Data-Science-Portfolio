{
 "cells": [
  {
   "attachments": {
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supriselib and Custom Recommender (Content-based) on MovieLens data\n",
    "![king-lip-h2z-BKEUR8s-unsplash](https://user-images.githubusercontent.com/40051540/89826625-25ebd080-db1c-11ea-8d54-3a838746ae62.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import math\n",
    "import heapq\n",
    "from tqdm import tqdm\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import LeaveOneOut\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import KNNBaseline\n",
    "from RecommenderMetrics import RecommenderMetrics\n",
    "\n",
    "# If the prediction is impossible\n",
    "from surprise import PredictionImpossible\n",
    "\n",
    "from surprise import AlgoBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9125, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_path = 'ml-latest-small/movies.csv'\n",
    "movies_DF = pd.read_csv(movies_path) \n",
    "print(movies_DF.shape)\n",
    "movies_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1       31     2.5  1260759144\n",
       "1       1     1029     3.0  1260759179\n",
       "2       1     1061     3.0  1260759182\n",
       "3       1     1129     2.0  1260759185\n",
       "4       1     1172     4.0  1260759205"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_path = 'ml-latest-small/ratings.csv'\n",
    "ratings_DF = pd.read_csv(ratings_path)\n",
    "ratings_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    # Define file path\n",
    "    movies_path = 'ml-latest-small/movies.csv'\n",
    "    links_path = 'ml-latest-small/links.csv'\n",
    "    ratings_path = 'ml-latest-small/ratings.csv'\n",
    "    \n",
    "    # Read file into Dataframe\n",
    "    movies_DF = pd.read_csv(movies_path)    \n",
    "    links_DF = pd.read_csv(links_path)     \n",
    "    ratings_DF = pd.read_csv(ratings_path)\n",
    "    \n",
    "    ratings_DF['movieId'] = ratings_DF['movieId'].astype(str)\n",
    "    ratings_DF['userId'] = ratings_DF['userId'].astype(str)\n",
    "    # Reader class is used to parse a file containing ratings\n",
    "    # The structure is as follows\n",
    "    # user ; item ; rating ; [timestamp]\n",
    "    # Dataset.load_from_file - loads a custom file\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    rating_dataset = Dataset.load_from_df(ratings_DF[['userId','movieId','rating']], reader=reader)\n",
    "    \n",
    "    return rating_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_popularity_rank():\n",
    "    popular_DF = pd.DataFrame(ratings_DF['movieId'].value_counts())\n",
    "    popular_DF.columns = ['count']\n",
    "    popular_DF.sort_values('count',ascending = False)\n",
    "    rank = [x for x in range(len(popular_DF))]\n",
    "    popular_DF['rank'] = rank\n",
    "    popular_DF.drop('count',axis = 1,inplace = True)\n",
    "    return popular_DF.to_dict('dict')['rank']\n",
    "#get_popularity_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anti_test_set(test_subject,train_set):\n",
    "    anti_test_set = []\n",
    "    avg_rating = train_set.global_mean\n",
    "    u = train_set.to_inner_uid(str(test_subject))\n",
    "    \n",
    "    # j is item inner id\n",
    "    # user_items is a list of inner item ids that test subject u rated\n",
    "    user_items = set([j for (j, _) in train_set.ur[u]])\n",
    "    \n",
    "    # anti-test set - (test subject, item that is not already rated by test subject, global mean)\n",
    "    for i in train_set.all_items():\n",
    "        if i not in user_items:\n",
    "            anti_test_set.append((train_set.to_raw_uid(u),train_set.to_raw_iid(i),avg_rating))\n",
    "            \n",
    "    return anti_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = 0\n",
    "movie_genre = defaultdict(list)\n",
    "genre_id_dict = defaultdict(int)\n",
    "\n",
    "def extract_genres(cols):\n",
    "    global max_id\n",
    "    genre_list = []\n",
    "    genres = cols[1].split('|')\n",
    "    for genre in genres:\n",
    "        if genre not in genre_id_dict:\n",
    "            genre_id_dict[genre] = max_id\n",
    "            max_id+=1\n",
    "        genre_list.append(genre_id_dict[genre])\n",
    "    movie_genre[cols[0]] = genre_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres():\n",
    "    movies_DF[['movieId','genres']].apply(extract_genres, axis = 1)\n",
    "    \n",
    "    # Convert integer-encoded genre lists to bitfields that we can treat as vectors\n",
    "    genre_no = len(genre_id_dict)\n",
    "    for (movie_id, genre_id_list) in movie_genre.items():\n",
    "        bitfield = [0] * max_id\n",
    "        for genre_id in genre_id_list:\n",
    "            bitfield[genre_id] = 1\n",
    "        movie_genre[movie_id] = bitfield \n",
    "    \n",
    "    return movie_genre\n",
    "#get_genres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_years = defaultdict(int)\n",
    "def extract_years(cols):\n",
    "    p = re.compile(r\"(?:\\((\\d{4})\\))?\\s*$\")\n",
    "    m = p.search(cols[1]).group(1)\n",
    "    if m:\n",
    "        movie_years[cols[0]] = int(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_years():\n",
    "    movies_DF[['movieId','title']].apply(extract_years, axis = 1) \n",
    "    return movie_years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Content_Based_KNN(AlgoBase):\n",
    "\n",
    "    def __init__(self, k = 40, sim_options = {}):\n",
    "        # Always call base method before doing anything.\n",
    "        AlgoBase.__init__(self)\n",
    "        self.k = k\n",
    "        \n",
    "    # Write logic that can be calculated independent of the user or item in questions\n",
    "    def fit(self, trainset):\n",
    "        # Here again: call base method before doing anything.\n",
    "        AlgoBase.fit(self, trainset)\n",
    "        genres = get_genres()\n",
    "        years = get_years() \n",
    "        \n",
    "        # compute similarity matrix 2x2 | item x item\n",
    "        self.similarities = np.zeros((self.trainset.n_items, self.trainset.n_items))\n",
    "        \n",
    "        # calculate pairwise similarity for all existing movies\n",
    "        for movie_a in tqdm(range(self.trainset.n_items)):\n",
    "        #for movie_a in range(100):\n",
    "           # if (movie_a% 100 == 0):\n",
    "                # print(movie_a, \" of \", self.trainset.n_items)\n",
    "            for movie_b in range(movie_a+1,self.trainset.n_items):\n",
    "                movie_a_id = int(self.trainset.to_raw_iid(movie_a))\n",
    "                movie_b_id = int(self.trainset.to_raw_iid(movie_b))\n",
    "                genre_similarity = self.compute_genre_similarity(movie_a_id, movie_b_id, genres)\n",
    "                year_similarity = self.compute_year_similarity(movie_a_id, movie_b_id, years)\n",
    "                self.similarities[movie_a, movie_b] =  genre_similarity * year_similarity\n",
    "                self.similarities[movie_b, movie_a] = self.similarities[movie_a, movie_b]\n",
    "                \n",
    "        print(\"...done.\")\n",
    "        return self\n",
    "    \n",
    "    def compute_genre_similarity(self, movie1, movie2, genres):\n",
    "        # Cosine Similarity\n",
    "        genres1 = genres[movie1]\n",
    "        genres2 = genres[movie2]\n",
    "        sumxx, sumxy, sumyy = 0, 0, 0\n",
    "        for i in range(len(genres1)):\n",
    "            x = genres1[i]\n",
    "            y = genres2[i]\n",
    "            sumxx += x * x\n",
    "            sumyy += y * y\n",
    "            sumxy += x * y\n",
    "        \n",
    "        return sumxy/math.sqrt(sumxx*sumyy)\n",
    "    \n",
    "    def compute_year_similarity(self, movie1, movie2, years):\n",
    "        diff = abs(years[movie1] - years[movie2])\n",
    "        sim = math.exp(-diff / 10.0)\n",
    "        return sim\n",
    "    \n",
    "    def estimate(self, u, i):\n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible('User and/or item is unkown.')\n",
    "        \"\"\"\n",
    "        k-nearest-neighbors:\n",
    "            a.\tCompute the similarity score between the movie you want to predict and all the movies the user rated\n",
    "            b.\tSelect k movies with the highest similarity to the movie we are making the prediction for.\n",
    "            c.\tTake weighted average of the similarity scores, weighing them by the rating the user gave them\n",
    "        \"\"\"\n",
    "        # a.\n",
    "        # Get all movies the user has rated \n",
    "        neighbors = []\n",
    "        for rating in self.trainset.ur[u]:\n",
    "            # Fetch similarity between predictant movie and movies user rated\n",
    "            genre_similarity = self.similarities[i,rating[0]]\n",
    "            # Append similarity score and rating\n",
    "            neighbors.append( (genre_similarity, rating[1]))\n",
    "        \n",
    "        # b.\n",
    "        # Extract the top-K most-similar ratings\n",
    "        k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[0])\n",
    "        \n",
    "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
    "            raise PredictionImpossible('User and/or item is unkown.')\n",
    "        \n",
    "        # c.\n",
    "        # Compute average sim score of K neighbors weighted by user ratings\n",
    "        sim_total = weighted_sum = 0\n",
    "        for (sim_score, rating) in k_neighbors:\n",
    "            if (sim_score > 0):\n",
    "                sim_total += sim_score\n",
    "                weighted_sum += sim_score * rating\n",
    "            \n",
    "        if (sim_total == 0):\n",
    "            raise PredictionImpossible('No neighbors')\n",
    "\n",
    "        predicted_rating = weighted_sum / sim_total\n",
    "\n",
    "        return predicted_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_id_name():\n",
    "    return movies_DF.set_index('movieId').to_dict('dict')['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done...\n"
     ]
    }
   ],
   "source": [
    "# Pick an arbitrary test subject\n",
    "test_subject = 85\n",
    "data = load_dataset()\n",
    "movie_id_name_dict = get_movie_id_name()\n",
    "algo = Content_Based_KNN()\n",
    "print(\"Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies user likes.....\n",
      "\n",
      "Jumanji (1995)\n",
      "Clear and Present Danger (1994)\n",
      "Mission: Impossible (1996)\n",
      "Terminator 2: Judgment Day (1991)\n",
      "Jurassic Park (1993)\n",
      "Fugitive, The (1993)\n",
      "True Lies (1994)\n",
      "Speed (1994)\n",
      "Star Trek: Generations (1994)\n",
      "GoldenEye (1995)\n",
      "Shawshank Redemption, The (1994)\n",
      "Stargate (1994)\n",
      "Pulp Fiction (1994)\n",
      "Léon: The Professional (a.k.a. The Professional) (Léon) (1994)\n",
      "Jerky Boys, The (1995)\n",
      "Braveheart (1995)\n",
      "Rock, The (1996)\n"
     ]
    }
   ],
   "source": [
    "movies_of_user_loves = ratings_DF[(ratings_DF['userId'] == test_subject) & (ratings_DF['rating'] > 4.0)][['movieId','rating']]\n",
    "movies_of_user_loves.sort_values(by = ['rating'],ascending = False,inplace = True)\n",
    "movies_of_user_loves  = movies_of_user_loves['movieId'].tolist()\n",
    "\n",
    "print('Movies user likes.....\\n')\n",
    "for movie in movies_of_user_loves:\n",
    "    print(movie_id_name_dict[movie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies user hates.....\n",
      "\n",
      "Grumpier Old Men (1995)\n",
      "Snow White and the Seven Dwarfs (1937)\n",
      "Lord of Illusions (1995)\n",
      "Dolores Claiborne (1995)\n",
      "Schindler's List (1993)\n",
      "Philadelphia (1993)\n",
      "Miracle on 34th Street (1994)\n",
      "Mortal Kombat (1995)\n",
      "Naked Gun 33 1/3: The Final Insult (1994)\n",
      "Wes Craven's New Nightmare (Nightmare on Elm Street Part 7: Freddy's Finale, A) (1994)\n",
      "Operation Dumbo Drop (1995)\n",
      "Nightmare Before Christmas, The (1993)\n",
      "Super Mario Bros. (1993)\n",
      "Beverly Hills Cop III (1994)\n",
      "Richie Rich (1994)\n",
      "Tank Girl (1995)\n",
      "While You Were Sleeping (1995)\n",
      "Poison Ivy II (1996)\n",
      "Nell (1994)\n",
      "Little Women (1994)\n",
      "Heavenly Creatures (1994)\n",
      "Prophecy, The (1995)\n",
      "Mighty Morphin Power Rangers: The Movie (1995)\n",
      "Casper (1995)\n",
      "Postman, The (Postino, Il) (1994)\n",
      "Oliver & Company (1988)\n"
     ]
    }
   ],
   "source": [
    "movies_of_user_hates = ratings_DF[(ratings_DF['userId'] == test_subject) & (ratings_DF['rating'] < 3.0)][['movieId','rating']]\n",
    "movies_of_user_hates.sort_values(by = ['rating'],ascending = False,inplace = True)\n",
    "movies_of_user_hates  = movies_of_user_hates['movieId'].tolist()\n",
    "\n",
    "print('Movies user hates.....\\n')\n",
    "for movie in movies_of_user_hates:\n",
    "    print(movie_id_name_dict[movie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9066/9066 [04:47<00:00, 31.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...done.\n",
      "\n",
      "We recommend:\n",
      "\n",
      "Presidio, The (1988)\n",
      "Femme Nikita, La (Nikita) (1990)\n",
      "Wyatt Earp (1994)\n",
      "Shooter, The (1997)\n",
      "Bad Girls (1994)\n",
      "The Hateful Eight (2015)\n",
      "True Grit (2010)\n",
      "Open Range (2003)\n",
      "Big Easy, The (1987)\n",
      "Point Break (1991)\n"
     ]
    }
   ],
   "source": [
    "# For making Top N Recommendations\n",
    "# --------------------------------\n",
    "full_train_set = data.build_full_trainset()\n",
    "anti_test_set_for_user  = anti_test_set(test_subject, full_train_set)\n",
    "\n",
    "algo.fit(full_train_set)\n",
    "predictions = algo.test(anti_test_set_for_user)\n",
    "\n",
    "recommendations = []\n",
    "print (\"\\nWe recommend:\\n\")\n",
    "for user_id, movie_id, avg_rating, estimated_rating, _ in predictions:\n",
    "    recommendations.append((int(movie_id), estimated_rating))\n",
    "\n",
    "recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for ratings in recommendations[:10]:\n",
    "    print(movies_DF[movies_DF['movieId']==ratings[0]]['title'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8211/8211 [03:37<00:00, 37.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...done.\n",
      "RMSE:  0.9375064084541399\n",
      "MAE:  0.7263424771236011\n"
     ]
    }
   ],
   "source": [
    "# For measuring accuracy\n",
    "# -----------------------\n",
    "train_set, test_set = train_test_split(data, test_size=.25, random_state=1)\n",
    "algo.fit(train_set)\n",
    "accuracy_predictions = algo.test(test_set)\n",
    "print('RMSE: ',RecommenderMetrics.RMSE(accuracy_predictions))\n",
    "print('MAE: ',RecommenderMetrics.MAE(accuracy_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9053/9053 [04:37<00:00, 32.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...done.\n",
      "0.0029806259314456036\n",
      "0.0029806259314456036\n",
      "0.0017032148179689163\n"
     ]
    }
   ],
   "source": [
    "# For measuring Hit Rate, Cumulative Hit Rate, Rating Hit Rate, Average Reciprocal Hit Rate\n",
    "# ------------------------------------------------------------------------------------------\n",
    "LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
    "for train, test in LOOCV.split(data):\n",
    "    LOOCV_train = train\n",
    "    LOOCV_test = test\n",
    "    #print(\"TRAIN:\", train, \"TEST:\", test)\n",
    "algo.fit(LOOCV_train)\n",
    "leave_one_out_predictions = algo.test(LOOCV_test)\n",
    "\n",
    "# Anti-test set: The ratings are all the ratings that are not in the trainset, \n",
    "#i.e. all the ratings rui where the user u is known, \n",
    "#the item i is known, but the rating rui is not in the trainset.\n",
    "LOOCV_anti_test_set = LOOCV_train.build_anti_testset()\n",
    "\n",
    "# Build predictions for all ratings not in the training set\n",
    "all_predictions_loocv = algo.test(LOOCV_anti_test_set)\n",
    "\n",
    "n = 10\n",
    "\n",
    "# Get top N Recommendations for each user to calculate HR, RHR,ARHR\n",
    "top_n_predicted = RecommenderMetrics.GetTopN(all_predictions_loocv, n)\n",
    "print(RecommenderMetrics.HitRate(top_n_predicted, leave_one_out_predictions))\n",
    "print(RecommenderMetrics.CumulativeHitRate(top_n_predicted, leave_one_out_predictions))\n",
    "print(RecommenderMetrics.AverageReciprocalHitRank(top_n_predicted, leave_one_out_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9066/9066 [04:31<00:00, 33.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...done.\n",
      "Computing Coverage\n",
      "Coverage:  0.9284649776453056\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing Diversity\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Diversity:  0.5700036080106995\n",
      "Novelty: 4651.525758069775\n"
     ]
    }
   ],
   "source": [
    "# For measuring Coverage, Diversity and Novelty\n",
    "# ----------------------------------------------\n",
    "\n",
    "n = 10\n",
    "full_train_set = data.build_full_trainset()\n",
    "full_anti_test_set = full_train_set.build_anti_testset()\n",
    "algo.fit(full_train_set)\n",
    "all_predictions_full = algo.test(full_anti_test_set)\n",
    "top_n_predicted = RecommenderMetrics.GetTopN(all_predictions_full, n)\n",
    "\n",
    "# Coverage\n",
    "print('Computing Coverage')\n",
    "print(\"Coverage: \", RecommenderMetrics.UserCoverage(top_n_predicted , full_train_set.n_users, ratingThreshold=4.0))\n",
    "\n",
    "# Diversity\n",
    "# Get similarities\n",
    "# Compute similarty matrix between items so we can measure diversity\n",
    "sim_options = {'name': 'cosine', 'user_based': False}\n",
    "sims_algo = KNNBaseline(sim_options=sim_options)\n",
    "sims_algo.fit(full_train_set)\n",
    "print('Computing Diversity')\n",
    "print('Diversity: ',RecommenderMetrics.Diversity(top_n_predicted, sims_algo))\n",
    "\n",
    "# Novelty\n",
    "# Get popularity ranking\n",
    "print('Novelty:',RecommenderMetrics.Novelty(top_n_predicted,get_popularity_rank()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
